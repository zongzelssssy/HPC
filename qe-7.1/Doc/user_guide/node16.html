<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2 Final//EN">

<!--Converted with LaTeX2HTML 2019.2 (Released June 5, 2019) -->
<HTML lang="EN">
<HEAD>
<TITLE>2.9 Installation tricks and problems</TITLE>
<META NAME="description" CONTENT="2.9 Installation tricks and problems">
<META NAME="keywords" CONTENT="user_guide">
<META NAME="resource-type" CONTENT="document">
<META NAME="distribution" CONTENT="global">

<META HTTP-EQUIV="Content-Type" CONTENT="text/html; charset=utf-8">
<META NAME="viewport" CONTENT="width=device-width, initial-scale=1.0">
<META NAME="Generator" CONTENT="LaTeX2HTML v2019.2">

<LINK REL="STYLESHEET" HREF="user_guide.css">

<LINK REL="previous" HREF="node15.html">
<LINK REL="next" HREF="node17.html">
</HEAD>

<BODY >
<!--Navigation Panel-->
<A
 HREF="node17.html">
<IMG WIDTH="37" HEIGHT="24" ALT="next" SRC="next.png"></A> 
<A
 HREF="node7.html">
<IMG WIDTH="26" HEIGHT="24" ALT="up" SRC="up.png"></A> 
<A
 HREF="node15.html">
<IMG WIDTH="63" HEIGHT="24" ALT="previous" SRC="prev.png"></A> 
<A ID="tex2html196"
  HREF="node1.html">
<IMG WIDTH="65" HEIGHT="24" ALT="contents" SRC="contents.png"></A>  
<BR>
<B> Next:</B> <A
 HREF="node17.html">3 Parallelism</A>
<B> Up:</B> <A
 HREF="node7.html">2 Installation</A>
<B> Previous:</B> <A
 HREF="node15.html">2.8 Running tests and</A>
 &nbsp; <B>  <A ID="tex2html197"
  HREF="node1.html">Contents</A></B> 
<BR>
<BR>
<!--End of Navigation Panel-->
<!--Table of Child-Links-->
<A ID="CHILD_LINKS"><STRONG>Subsections</STRONG></A>

<UL>
<LI><A ID="tex2html198"
  HREF="node16.html#SECTION00039100000000000000">2.9.1 All architectures</A>
<LI><A ID="tex2html199"
  HREF="node16.html#SECTION00039200000000000000">2.9.2 Linux PC</A>
<UL>
<LI><A ID="tex2html200"
  HREF="node16.html#SECTION00039210000000000000">2.9.2.1 Linux PCs with gfortran</A>
<LI><A ID="tex2html201"
  HREF="node16.html#SECTION00039220000000000000">2.9.2.2 Linux PCs with Intel compiler (ifort)</A>
<LI><A ID="tex2html202"
  HREF="node16.html#SECTION00039230000000000000">2.9.2.3 Linux PCs with MKL libraries</A>
<LI><A ID="tex2html203"
  HREF="node16.html#SECTION00039240000000000000">2.9.2.4 Linux PCs with AMD processors</A>
</UL>
<BR>
<LI><A ID="tex2html204"
  HREF="node16.html#SECTION00039300000000000000">2.9.3 Linux PC clusters with MPI</A>
<LI><A ID="tex2html205"
  HREF="node16.html#SECTION00039400000000000000">2.9.4 Microsoft Windows</A>
<LI><A ID="tex2html206"
  HREF="node16.html#SECTION00039500000000000000">2.9.5 Mac OS</A>
<LI><A ID="tex2html207"
  HREF="node16.html#SECTION00039600000000000000">2.9.6 Cray machines</A>
<LI><A ID="tex2html208"
  HREF="node16.html#SECTION00039700000000000000">2.9.7 Obsolescent architectures</A>
<UL>
<LI><A ID="tex2html209"
  HREF="node16.html#SECTION00039710000000000000">2.9.7.1 Intel Xeon Phi</A>
<LI><A ID="tex2html210"
  HREF="node16.html#SECTION00039720000000000000">2.9.7.2 IBM BlueGene</A>
</UL></UL>
<!--End of Table of Child-Links-->
<HR>

<H2><A ID="SECTION00039000000000000000">
2.9 Installation tricks and problems</A>
</H2>

<P>

<H3><A ID="SECTION00039100000000000000">
2.9.1 All architectures</A>
</H3>

<UL>
<LI>Working Fortran and C compilers must be present in your PATH.
If <TT>configure</TT> says that you have no working compiler, well,
you have no working compiler, at least not in your PATH, and
not among those recognized by <TT>configure</TT>.
</LI>
<LI>If you get <EM>Compiler Internal Error</EM> or similar messages: your
compiler version is buggy. Try to lower the optimization level, or to
remove optimization just for the routine that has problems. If it
doesn't work, or if you experience weird problems at run time, try to
install patches for your version of the compiler (most vendors release
at least a few patches for free), or to upgrade to a more recent
compiler version.
</LI>
<LI>If you get error messages at the loading phase that look like
<EM>file XYZ.o: unknown / not recognized/ invalid / wrong
file type / file format / module version</EM>,
one of the following things have happened:

<OL>
<LI>you have leftover object files from a compilation with another
  compiler: run <TT>make clean</TT> and recompile.
</LI>
<LI><TT>make</TT> did not stop at the first compilation error (it may
happen in some software configurations). Remove the file *.o
that triggers the error message, recompile, look for a
compilation error.
</LI>
</OL>
If many symbols are missing in the loading phase: you did not specify the
location of all needed libraries (LAPACK, BLAS, FFTW, machine-specific
optimized libraries), in the needed order.
Note that Q<SMALL>UANTUM </SMALL>ESPRESSO is self-contained (with the exception of MPI libraries for
parallel compilation): if system libraries are missing, the problem is in
your compiler/library combination or in their usage, not in Q<SMALL>UANTUM </SMALL>ESPRESSO.
</LI>
<LI>If you get <EM>Segmentation fault</EM> or similar errors
in the provided tests and examples: your compiler, or
your mathematical libraries, or MPI libraries,
or a combination thereof, is buggy, or there is some
software incompatibility. Although one can never rule out
the presence of subtle bugs in Q<SMALL>UANTUM </SMALL>ESPRESSO that are not revealed during
the testing phase, it is very unlikely
that this happens on the provided tests and examples.
</LI>
<LI>If all test fails, look into the output and error files:
there is some dumb reason for failure.
</LI>
<LI>If most test pass but some fail, again: look into the output
and error files. A frequent source of trouble is complex function
<TT>zdotc</TT>. See the "Linux PCs with gfortran compilers" paragraph.
</LI>
</UL>

<P>

<H3><A ID="SECTION00039200000000000000">
2.9.2 Linux PC</A>
</H3>

<P>
Both AMD and Intel CPUs, 32-bit and 64-bit, are supported and work,
either in 32-bit emulation and in 64-bit mode. 64-bit executables
can address a much larger memory space than 32-bit executable, but
there is no gain in speed.
Beware: the default integer type for 64-bit machine is typically
32-bit long. You should be able to use 64-bit integers as well,
but it is not guaranteed to work and will not give
any advantage anyway.

<P>
Currently, <TT>configure</TT> supports Intel (ifort), NAG (nagfor), NVidia
(nvfortran, formerly PGI pgf90), ARM (armflang),
and gfortran compilers. Pathscale, Sun Studio, AMD Open64, are no
longer supported after v.6.2: g95, since v.6.1.

<P>
Intel MKL mathematical libraries are supported. ACML support must be
considered as obsolete.

<P>
It is usually convenient to create semi-statically linked executables (with only
libc, libm, libpthread dynamically linked). If you want to produce a binary
that runs on different machines, compile it on the oldest machine you have
(i.e. the one with the oldest version of the operating system).

<P>

<H4><A ID="SECTION00039210000000000000">
2.9.2.1 Linux PCs with gfortran</A>
</H4>

<P>
Gfortran v.4.8.5, still found on CentOS machines, no longer compiles
Q<SMALL>UANTUM </SMALL>ESPRESSO v.6.6 or later, due to a gfortran bug. You need at least gfortran v.4.9.X.

<P>
"There is a known incompatibility problem between different calling
convention for Fortran functions that return complex values [...]
If your code crashes during a call to <TT>zdotc</TT>,
recompile Q<SMALL>UANTUM </SMALL>ESPRESSO using the internal BLAS and LAPACK routines
(using <TT>configure</TT> options <TT>&ndash;with-internal-blas</TT> and
<TT>&ndash;with-internal-lapack</TT>)
to see if the problem disappears; or, add the <TT>-ff2c</TT> flag"
(info by Giovanni Pizzi, Jan. 2013).
You may also consider replacing the offending calls to <TT>zdotc</TT>
with fortran intrinsic <TT>dot_product</TT>.

<P>
If you want to use MKL libraries together with gfortran,
link <TT>-lmkl_gf_lp64</TT>, not <TT>-lmkl_intel_lp64</TT>.

<P>

<H4><A ID="SECTION00039220000000000000">
2.9.2.2 Linux PCs with Intel compiler (ifort)</A>
</H4>

<P>
The Intel compiler ifort <TT>http://software.intel.com/</TT>
produces fast executables, at least on Intel CPUs, but not all versions
work as expected. In particular, ifort versions earlier than v.15
miscompile the new XML code in QE v.6.4 and later and should not be
used any longer. In case of trouble, update your version
with the most recent patches. Since each major release of ifort
differs a lot from the previous one, compiled objects from different
releases may be incompatible and should not be mixed.

<P>
If <TT>configure</TT> doesn't find the compiler, or if you get
<EM>Error loading shared libraries</EM> at run time, you may have
forgotten to execute the script that
sets up the correct PATH and library path. Unless your system manager has
done this for you, you should execute the appropriate script &ndash; located in
the directory containing the compiler executable &ndash; in your
initialization files. Consult the documentation provided by Intel.

<P>
The warning: <EM>feupdateenv is not implemented and will always fail</EM>,
can be safely ignored. Complains about ``recommended formats'' may also
be ignored.

<P>

<H4><A ID="SECTION00039230000000000000">
2.9.2.3 Linux PCs with MKL libraries</A>
</H4>
On Intel CPUs it is very convenient to use Intel MKL libraries
(freely available at
<TT>https://software.intel.com/en-us/performance-libraries</TT>).
MKL libraries can be used also with non-Intel compilers.
They work also for AMD CPU, selecting the appropriate machine-optimized
libraries: see ``Linux PCs with AMD processors''.

<P>
<TT>configure</TT> properly detects only recent (v.12 or later) MKL libraries,
as long as the $MKLROOT environment variable is set in the current shell.
Normally this environment variable is set by sourcing the Intel MKL or Intel
Parallel Studio environment script.
By default the non-threaded version of MKL is linked, unless option
<TT>configure &ndash;with-openmp</TT> is specified. In case of trouble,
refer to the following web page to find the correct way to link MKL:
<BR><TT>http://software.intel.com/en-us/articles/intel-mkl-link-line-advisor/</TT>.

<P>
For parallel (MPI) execution on multiprocessor (SMP) machines, set the
environment variable OMP_NUM_THREADS to 1 unless you know how to run
MPI+OpenMP. See Sec.<A HREF="node17.html#Sec:para">3</A> for more info on this
and on the difference between MPI and OpenMP parallelization.

<P>
If you get a mysterious "too many communicators" error and a
subsequent crash: there is a bug in Intel MPI and MKL 2016 update 3.
See this thread and the links quoted therein:
<code>http://www.mail-archive.com/pw_forum@pwscf.org/msg29684.html</code>.

<P>

<H4><A ID="SECTION00039240000000000000">
2.9.2.4 Linux PCs with AMD processors</A>
</H4>
For AMD CPUs you may find convenient to link AMD acml libraries
(can be freely downloaded from AMD web site).
<TT>configure</TT> should recognize properly installed acml libraries.
UPDATE (February 2020): acml have been discontinued. There are new
libraries called AMD Optimizing CPU Libraries (AOCL), tuned for the
AMD EPYC processor family.
`` Recently I played around with some AMD EPYC cpus and the bad thing
is that I also saw some strange numbers when using libflame/aocl 2.1.
(...) Since version 2020 the MKL performs rather well when using AMD cpus,
 however, if you want to get the best performance you have to additionally set:
<PRE>
export MKL_DEBUG_CPU_TYPE=5
</PRE>
which gives an additional 10-20% speedup with MKL 2020,
while for earlier versions the speedup is greater than 200%.
[...] Another note, there seem to be problems using FFTW interface
of MKL with  AMD cpus. To get around this problem, one has to
additionally set
<PRE>
export MKL_CBWR=AUTO
</PRE>
`` (Info by Tobias Klöffel, Feb. 2020)

<P>

<H3><A ID="SECTION00039300000000000000"></A>
<A ID="SubSec:LinuxPCMPI"></A>
<BR>
2.9.3 Linux PC clusters with MPI
</H3>
PC clusters running some version of MPI are a very popular
computational platform nowadays. Q<SMALL>UANTUM </SMALL>ESPRESSO is known to work
with at least two of the major MPI implementations (MPICH, LAM-MPI),
plus with the newer MPICH2 and OpenMPI implementation.
<TT>configure</TT> should automatically recognize a properly installed
parallel environment and prepare for parallel compilation.
Unfortunately this not always happens. In fact:

<UL>
<LI><TT>configure</TT> tries to locate a parallel compiler in a logical
  place with a logical name, but if it has a strange names or it is
  located  in a strange location, you will have to instruct <TT>configure</TT>   to find it. If there is no parallel Fortran compiler, you will have
  to install one.
</LI>
<LI><TT>configure</TT> tries to locate libraries (both mathematical and
  parallel libraries) in the usual places with usual names, but if
  they have strange names or strange locations, you will have to
  rename/move them, or to instruct <TT>configure</TT> to find them. If MPI
  libraries are not found,
  parallel compilation is disabled.
</LI>
<LI><TT>configure</TT> tests that the compiler and the libraries are
  compatible (i.e. the compiler may link the libraries without
  conflicts and without missing symbols). If they aren't and the
  compilation fails, <TT>configure</TT> will revert to serial compilation.
</LI>
</UL>

<P>
Apart from such problems, Q<SMALL>UANTUM </SMALL>ESPRESSO compiles and works on all non-buggy, properly
configured hardware and software combinations. In some cases you may have to
recompile MPI libraries: not all MPI installations contain support for
the Fortran compiler of your choice (or for any Fortran compiler
at all!).

<P>
If Q<SMALL>UANTUM </SMALL>ESPRESSO does not work for some reason on a PC cluster,
try first if it works in serial execution. A frequent problem with parallel
execution is that Q<SMALL>UANTUM </SMALL>ESPRESSO does not read from standard input,
due to the configuration of MPI libraries: see Sec.<A HREF="node22.html#SubSec:badpara">3.5</A>.
If you are dissatisfied with the performances in parallel execution,
see Sec.<A HREF="node17.html#Sec:para">3</A> and in particular Sec.<A HREF="node22.html#SubSec:badpara">3.5</A>.

<P>

<H3><A ID="SECTION00039400000000000000"></A>
<A ID="SubSec:Windows"></A>
<BR>
2.9.4 Microsoft Windows
</H3>
Since February 2020 Q<SMALL>UANTUM </SMALL>ESPRESSO can be compiled on MS-Windows 10 using PGI 19.10
Community Edition (freely downloadable). <TT>configure</TT> works with the bash
script provided by PGI but the <TT>configure</TT> of FoX fails: use script
<TT>install/build_fox_with_pgi.sh</TT> to manually compile FoX.

<P>
Another option: use MinGW/MSYS. Download the installer from
<TT>https://osdn.net/projects/mingw/</TT>, install MinGW, MSYS, gcc and
gfortran. Start a shell window; run "./configure"; edit <TT>make.inc</TT>;
uncommenting the second definition of TOPDIR (the first one introduces a
final "/" that Windows doesn't like); run "make". Note that on some Windows
the code fails when checking that <TT>tmp_dir</TT> is writable, for unclear
reasons.

<P>
Another option is Cygwin, a UNIX environment which runs under Windows: see
<BR><TT>http://www.cygwin.com/</TT>.

<P>
Windows-10 users may also enable the Windows Subsystem for Linux (see here:
<BR><TT>https://docs.microsoft.com/en-us/windows/wsl/install-win10</TT>),
install a Linux distribution, compile Q<SMALL>UANTUM </SMALL>ESPRESSO as on Linux. It works very well.

<P>
As a final option, one can use Quantum Mobile:
<BR><TT>https://www.materialscloud.org/work/quantum-mobile</TT>.

<P>

<H3><A ID="SECTION00039500000000000000">
2.9.5 Mac OS</A>
</H3>

<P>
"I have had some success compiling pw.x on the newish apple hardware.
Running run-tests-pw-parallel resulted in all but 3 tests passed (3 unknown).
QE6.7 works out of the box:

<UL>
<LI>Install homebrew
</LI>
<LI>Using homebrew install gcc (11.2.0), open-mpi (4.1.1_2), 
fftw3 (3.3.10), and veclibfort (0.4.2_7)
</LI>
</UL>
To configure QE: 
<PRE>
./configure FC=mpif90 CC=mpicc CPP=cpp-11 BLAS_LIBS="-L/opt/homebrew/lib
           -lveclibfort" LIBDIRS=/opt/homebrew/lib
</PRE>
Current develop branch needed two changes:

<OL>
<LI>The script external/devxlib/config/config.sub is outdated, 
and needs to be adjusted to correctly parse the machine information. 
I pulled a more up-to-date version from iains/gcc-darwin-arm64 github repo
<BR></LI>
<LI>PW/src/efermig.f90 needed to be compiled without optimization -O0. 
No idea why at the moment."
</LI>
</OL>
(Info by John Vinson, NIST)

<P>
Mac OS-X machines with gfortran or with the Intel compiler ifort
and MKL libraries should work, but "your mileage may vary", depending
upon the specific software stack you are using. Parallel compilation
with OpenMPI should also work.

<P>
If you get an error like
<PRE>
  clang: error: no input files
  make[1]: *** [laxlib.fh] Error 1
  make: *** [libla] Error 1i
</PRE>
redefine <TT>CPP</TT> as <TT>CPP=gcc -E</TT> in <TT>make.inc</TT>.

<P>
Gfortran information and binaries for Mac OS-X here:
<TT>http://hpc.sourceforge.net/</TT> and
<TT>https://wiki.helsinki.fi/display/HUGG/GNU+compiler+install+on+Mac+OS+X</TT>.

<P>
Mysterious crashes in <TT>zdotc</TT> are due to a known incompatibility of
complex functions with some optimized BLAS. See the "Linux PCs with gfortran"
paragraph.

<P>

<H3><A ID="SECTION00039600000000000000">
2.9.6 Cray machines</A>
</H3>

<P>
For recent Cray machines, use <TT>./configure ARCH=craype</TT>.
This selects the <TT>ftn</TT> compiler, that typically uses
the <TT>crayftn</TT> compiler but may also use other ones,
depending upon the site and personal environment.

<P>
''Now, despite what people can imagine, every CRAY machine deployed can
have different environment. For example on the machine I usually use
for tests [...] I do have to unload some modules to make QE running
properly. On another CRAY [...] there is also Intel compiler as option
and the system is slightly different compared to the other.'' 
(info by Filippo Spiga)

<P>
With the <code>PrgEnv-cray</code> module, v.6.0.10, you get an internal compiler 
error in <code>esm_stres_mod.f90</code>. If so, reduce the optimization level
for that specific routine from <code>-O3</code> to <code>-O1</code>.

<P>
If you want to use the Intel compiler instead, try something like:
<PRE>
$ module swap PrgEnv-cray PrgEnv-intel
$ ./configure ARCH=craype [--enable-openmp --enable-parallel --with-scalapack]
</PRE>

<P>
Old Cray machines: T3D, T3E, X1, etc, are no longer supported.

<P>

<H3><A ID="SECTION00039700000000000000">
2.9.7 Obsolescent architectures</A>
</H3>

<P>

<H4><A ID="SECTION00039710000000000000">
2.9.7.1 Intel Xeon Phi</A>
</H4>

<P>
For Intel Xeon CPUs with Phi coprocessor, see this link:
<BR><TT>https://software.intel.com/en-us/articles/explicit-offload-for-quantum-espresso</TT>.

<P>
There are three ways of compiling:

<UL>
<LI><EM>offload</EM> mode, executed on main CPU and offloaded onto coprocessor
"automagically";
</LI>
<LI><EM>native</EM> mode, executed completely on coprocessor;
</LI>
<LI><EM>symmetric</EM> mode, requiring creation of both binaries.
</LI>
</UL>
"You can take advantage of the offload mode using the <TT>libxphi</TT>
library. This library offloads the BLAS/MKL functions on the Xeon Phi
platform hiding the latency times due to the communication. You just
need to compile this library and then to link it dynamically. The
library works with any version of QE. Libxphi is available from
<TT>https://github.com/cdahnken/libxphi</TT>. Some documentation is
available therein.

<P>
Instead, if you want to compile a native version of QE, you just need
to add the <TT>-mmic</TT> flag and cross compile. If you want to use
the symmetric mode, you need to compile twice: with and without the
<TT>-mmic</TT> flag". "[...] everything, i.e. code+libraries, must be
cross-compiled with the <TT>-mmic</TT> flag. In my opinion, it's pretty
unlikely that native mode can outperform the execution on the standard
Xeon cpu. I strongly suggest to use the Xeon Phi in offload mode, for now"
(info by Fabio Affinito, March 2015).

<P>

<H4><A ID="SECTION00039720000000000000">
2.9.7.2 IBM BlueGene</A>
</H4>

<P>
The current <TT>configure</TT> was working on the machines at CINECA and at Jülich.
For other machines, you may need something like
<PRE>
  ./configure ARCH=ppc64-bg BLAS_LIBS=...  LAPACK_LIBS=... \
              SCALAPACK_DIR=... BLACS_DIR=..."
</PRE>
where the various *_LIBS and *_DIR "suggest" where the various libraries
are located.

<P>

<P>
<HR>
<!--Navigation Panel-->
<A
 HREF="node17.html">
<IMG WIDTH="37" HEIGHT="24" ALT="next" SRC="next.png"></A> 
<A
 HREF="node7.html">
<IMG WIDTH="26" HEIGHT="24" ALT="up" SRC="up.png"></A> 
<A
 HREF="node15.html">
<IMG WIDTH="63" HEIGHT="24" ALT="previous" SRC="prev.png"></A> 
<A ID="tex2html196"
  HREF="node1.html">
<IMG WIDTH="65" HEIGHT="24" ALT="contents" SRC="contents.png"></A>  
<BR>
<B> Next:</B> <A
 HREF="node17.html">3 Parallelism</A>
<B> Up:</B> <A
 HREF="node7.html">2 Installation</A>
<B> Previous:</B> <A
 HREF="node15.html">2.8 Running tests and</A>
 &nbsp; <B>  <A ID="tex2html197"
  HREF="node1.html">Contents</A></B> 
<!--End of Navigation Panel-->

</BODY>
</HTML>
